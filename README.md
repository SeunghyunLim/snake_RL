# Snake 강화학습 메인 페이지

## Introduction
BRM 연구실에서 뱀을 강화학습하기 위해서 만든 페이지입니다.

저희가 강화학습을 연구에 적용하기 위해서 여러 플랫폼을 이용해보았습니다. 이런 플랫폼을 이용한 경험은 다음과 같습니다.
강화학습에 대해 여러 연구자들이 관심을 갖기 시작하여 중요한 key 개념이 되는 보상 함수라던지 Action, Observation에 대한 구현은 어떤 플랫폼을 사용해도 구현할 수 있었습니다.
이는 다른 연구자들이 강화학습 전용 플랫폼 없이 Python 스크립트만을 이용해도 간단한 Q-net 학습이 가능한 것을 확인시겼기 때문에, 이를 넘어서 Python과 함께 DL 프레임워크인 Pytorch, tensorflow를 활용하면 간단한 인공 신경망을 이용한 강화학습을 할 수 있겠다는 것은 쉽게 생각할 수 있기 때문입니다. 하지만, 강화학습을 저희 연구실에서 연구하는 주제인 로봇에 강화학습을 적용시키기 위해서는 여러 문제점이 존재했습니다. 그 중에서 가장 핵심적인 문제는 저희가 사용할 수 있는 동역학 시뮬레이터의 부재입니다.
물론 ROS에서 기본으로 제공하는 Gazebo와 같은 범용 목적의 시뮬레이터를 활용하면, 우리가 모델링한 URDF파일을 이용해 관절에 전류를 인가했을 때, 로봇이 어느 동작을 취할지 시뮬레이션을 통해 예측할 수 있습니다. 하지만, 실제 연구를 진행할 때, 발생한 문제는 다음과 같습니다.

* 시뮬레이터가 지나치게 크다(무겁다)는 문제가 있습니다. 우리는 우리가 학습하고자하는 모델에 가까운 시뮬레이터를 사용하고 싶습니다. 하지만 시뮬레이터가 지나치게 발전한 까닭에 우리는 시뮬레이터와 통신을 진행하기 위해서 정말 상위 계층인 TCP 혹은 UDP를 활용해 Web socket 통신을 진행하고 있습니다. 이는 Application을 제작한다면 정말 유용한 방법일지 모릅니다. 하지만, 우리와 같이 모델 학습을 진행시키기 위해서 Web socket 통신을 이용하는 것은 개발에 어렵움이 있을 뿐더러 Web socket에 접근하는 타이밍까지 고려해야한다는 추가적인 문제가 생기게 됩니다.

* 시뮬레이터가 크다는 문제점으로 생기는 추가적인 문제점을 또 있습니다. 우리는 강화학습을 통해서 여러 State에서 Action을 선택했을 때 발생하는 보상에 대해서 민감하게 학습을 진행하고 싶습니다. 하지만, 이런 큰 크기의 시뮬레이터로 인해서 우리가 원했던 시간의 보상 값을 확실하게 얻었는지 확실하게 알 수 없습니다. 물론 추후에 Gazebo 시뮬레이터가 Real-time을 보장하는 업데이트를 진행할 수 있겠지만, 현재로썬 안되는 것으로 보입니다.

* 시뮬레이터마다 추구하는 방향성이 다르다. Gazebo, V-rep, Recurdyn 모두 동역학 시뮬레이터지만 각자의 장점이 있습니다. Gazebo같은 경우 ROS에 기본적으로 제공하는 시뮬레이터이기 때문에 ROS와 연동성이 다 시뮬레이터보다 좋은 것으로 보이고, V-rep의 경우 시뮬레이터에서 로봇에 명령을 줄 수 있는 간단한 Script까지 작성할 수 있는 all-in-one 해결 방법을 제공하며, Recurdyn의 경우 다른 시뮬레이터는 아직 빈약하게 지원하는 유체의 이동까지 시뮬레이션할 수 있는 것으로 보입니다. 하지만 이 3 시뮬레이터는 큰 몸집으로 작은 프로그램에 통합되기 어렵습니다.

이런 문제점으로 우리는 많은 조사를 통해서 Deepmind에서 강화학습을 이용한 Control set을 제공한다는 사실을 확인했습니다. Deepmind 연구팀은 동역학 시뮬레이터지만, 그 크기가 9mb가 안되는 MuJoCo라는 시뮬레이터를 활용하는 것으로 보입니다. 예제 코드를 확인하면, 다른 시뮬레이터를 활용하는 것과 다르게 작은 크기로 쉽게 코드 내부에서 활용할 수 있는 것으로 보입니다.

이런 이유로 현재 MuJoCo를 활용하여 강화학습을 진행하고자 합니다.

    notes:
    20210707;
    Mujoco에 대한 학습에 어느정도 진전이 있었습니다. 다행히도, 시뮬레이터를 활용하는 방법은 여타 시뮬레이터와 다르지 않습니다. 이전에 활용했던 Gazebo와 사용 방법은 비슷하지만, 가장 큰 장점은 시뮬레이션 스크립트와 시뮬레이션과 밀접성을 꼽을 수 있습니다. 이전 Gazebo를 활용한 연구에서는 로봇 관절에 명령을 보내기 위해서 ROS Master라는 거대한 파라미터 서버를 거쳐 통신했었습니다. ROS는 이런 거대한 파라미터 서버를 통해서 여러 학제간의 연구 성과를 쉽게 공유할 수 있다는 장점으로 빠른 성장을 하고 있습니다. 하지만, 강화학습에서는 사실 이런 거대한 파라미터 서버가 단점으로 작용합니다. Mujoco는 시뮬레이터를 Python 스크립트에서 밀접하게 사용할 수 있도록 Python 바인딩을 제공합니다. 이런 바인딩을 이용해서 우리는 우리가 원할 때 시뮬레이터에 명령을 전송할 수 있습니다. 현재 저희는 뱀 로봇의 Gait를 스크립트화 하여서 Mujoco를 통해 결과 값을 원하는 시간에 받아 Reward를 확인할 수 있게 하였습니다.